<!-- <div style="max-width: 100%; width: 100%;">

<strong>AI system software ü§πüèª</strong>

In recent years, datacenters have evolved to accommodate a variety of heterogeneous workloads and devices. A prominent example is distributed deep learning training, which enables the development of large-scale AI models like GPT, DALL-E or LLaMA, demanding over 530 billion hyperparameters and utilizing hundreds of GPU nodes. As a result, optimizing infrastructure utilization and efficiency has become crucial. However, recent data from major cloud providers such as Microsoft and Alibaba reveal average GPU utilization rates of only 52.4% and 25.4%, respectively. This underutilization signifies a considerable waste of datacenter infrastructure resources, highlighting the need for more effective strategies to improve efficiency and utilization.

One of the primary challenges in optimizing system infrastructure is that deep learning workloads have not yet been characterized by system software. Despite significant advancements in the field, determining the optimal training configuration, such as the GPU type and number of GPUs, remains unknown, resulting in unpredictable training times. This issue makes it impossible to optimize scheduling or system techniques on AI tasks. Also, severe overallocation of GPUs exist in datacenters. These resource inefficiency problems necessitate more efficient system management strategies.

The following are representative technologies from our research.
<div style="display: flex; gap: 10px; justify-content: center;">

  <img src="static/workload.jpg" alt="Image 1" style="width: 30%;"/>
  <img src="static/scheduling.jpg" alt="Image 2" style="width: 30%;"/>
  <img src="static/placement.jpg" alt="Image 3" style="width: 30%;"/>

</div>

</div> -->

---
title: Tour
type: landing
sections:
  - block: blank
    design:
      container: false  # ‚úÖ full-widthÎ°ú ÌçºÏßÄÍ≤å ÌïòÎäî ÌïµÏã¨ ÏÑ§Ï†ï
    content: |
      <div style="padding: 40px; text-align: center;">

      <h1><strong>AI system software ü§πüèª</strong></h1>

      <p style="max-width: 900px; margin: auto;">
      In recent years, datacenters have evolved to accommodate a variety of heterogeneous workloads and devices. A prominent example is distributed deep learning training, which enables the development of large-scale AI models like GPT, DALL-E or LLaMA, demanding over 530 billion hyperparameters and utilizing hundreds of GPU nodes. As a result, optimizing infrastructure utilization and efficiency has become crucial. However, recent data from major cloud providers such as Microsoft and Alibaba reveal average GPU utilization rates of only 52.4% and 25.4%, respectively. This underutilization signifies a considerable waste of datacenter infrastructure resources, highlighting the need for more effective strategies to improve efficiency and utilization.

      One of the primary challenges in optimizing system infrastructure is that deep learning workloads have not yet been characterized by system software. Despite significant advancements in the field, determining the optimal training configuration, such as the GPU type and number of GPUs, remains unknown, resulting in unpredictable training times. This issue makes it impossible to optimize scheduling or system techniques on AI tasks. Also, severe overallocation of GPUs exist in datacenters. These resource inefficiency problems necessitate more efficient system management strategies.

      The following are representative technologies from our research.
      </p>

      <div style="display: flex; justify-content: center; gap: 20px; margin-top: 40px;">
        <img src="/uploads/workload.png/workload.jpg" style="width: 30%;" />
        <img src="/uploads/scheduling.jpg" style="width: 30%;" />
        <img src="/uploads/placement.jpg" style="width: 30%;" />
      </div>

      </div>
---
<!-- ---
title: Tour
date: 2022-10-24

type: landing

sections:
  - block: slider
    content:
      slides:
      - title: üëã Research
        content: 
        align: center
        # background:
        #   image:
        #     filename: coders.jpg
        #     filters:
        #       brightness: 0.7
        #   position: right
        #   color: '#666'
      # - title: Lunch & Learn ‚òïÔ∏è
      #   content: 'Share your knowledge with the group and explore exciting new topics together!'
      #   align: left
      #   background:
      #     image:
      #       filename: contact.jpg
      #       filters:
      #         brightness: 0.7
      #     position: center
      #     color: '#555'
      # - title: World-Class Semiconductor Lab
      #   content: 'Just opened last month!'
      #   align: right
      #   background:
      #     image:
      #       filename: welcome.jpg
      #       filters:
      #         brightness: 0.5
      #     position: center
      #     color: '#333'
      #   link:
      #     icon: graduation-cap
      #     icon_pack: fas
      #     text: Join Us
      #     url: ../contact/
    # design:
    #   # Slide height is automatic unless you force a specific height (e.g. '400px')
    #   slide_height: ''
    #   is_fullscreen: false
    #   # Automatically transition through slides?
    #   loop: false
    #   # Duration of transition between slides (in ms)
    #   interval: 2000
--- -->
